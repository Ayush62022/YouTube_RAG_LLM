{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "'''\n",
    "This script demonstrates using the dotenv and os modules to manage environment variables effectively. \n",
    "It loads an API key and stores URLs for two YouTube videos, showcasing simple data handling and preparation for video-related operations.\n",
    "'''\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=1oj3uLVTH4o\"  \n",
    "YOUTUBE_VIDEO1=\"https://youtu.be/46gAXft4TMA?si=JoMbLtJELdDqCjVq\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seting up The Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "'''\n",
    "This snippet initializes an instance of the ChatOpenAI class from the langchain_openai library. \n",
    "It uses an API key and specifies a model version (\"gpt-3.5-turbo\") to create a chat model object. \n",
    "This object can be used to interact with OpenAI's GPT-3.5 Turbo model for various natural language processing tasks,\n",
    "such as generating text, answering questions, or engaging in conversation.\n",
    "'''\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Los Angeles Dodgers won the 2020 World Series during the COVID-19 pandemic.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can test the model by asking a simple question.\n",
    "model.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Dodgers won the World Series during the COVID-19 pandemic in 2020. They defeated the Tampa Bay Rays in six games to win their first championship since 1988.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "'''\n",
    "This snippet sets up an `StrOutputParser` to parse outputs, connects it with a `ChatOpenAI` model using a chain, \n",
    "and invokes a question about the World Series winner during the COVID-19 pandemic. It illustrates chaining model output to a parser for direct processing.\n",
    "'''\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "chain.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing prompt templates\n",
    "We want to provide the model with some context and the question. Prompt templates are a simple way to define and reuse prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susana'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"Mary's sister is Susana\",\n",
    "    \"question\": \"Who is Mary's sister?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining chains\n",
    "We can combine different chains to create more complex workflows. For example, let's create a second chain that translates the answer from the first chain into a different language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate {answer} to {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary has one sister, Susana.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain = (\n",
    "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
    "        \"question\": \"How many sisters does Mary have?\",\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing the YouTube Video\n",
    "The context we want to send the model comes from a YouTube video. Let's download the video and transcribe it using OpenAI's Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "\n",
    "'''\n",
    "This snippet is designed to transcribe the audio of a YouTube video into text using the Whisper model. It first checks if a transcription \n",
    "file already exists to avoid unnecessary processing. If the file doesn't exist, it uses pytube to download the audio stream of the specified \n",
    "YouTube video. The audio is then transcribed using OpenAI's Whisper model loaded with the \"base\" configuration, chosen for its balance between \n",
    "speed and accuracy. The transcription is saved to a file named \"transcription.txt\". This process demonstrates integrating different tools and \n",
    "libraries to perform complex tasks like downloading online content and applying advanced machine learning models for audio transcription.\n",
    "'''\n",
    "\n",
    "# Let's do this only if we haven't created the transcription file yet.\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # Let's load the base model. This is not the most accurate\n",
    "    # model but it's fast.\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a hal'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "After creating a transcription of a YouTube video's audio, this code snippet opens the generated \"transcription.txt\" file to read its contents. \n",
    "It then assigns the entire transcription text to a variable named 'transcription'. Finally, it extracts and displays the first 100 characters \n",
    "of the transcription to provide a quick preview or snippet of the transcribed audio content. This could be useful for verifying the transcription's \n",
    "initial content or for quick inspection purposes without needing to read the entire file.\n",
    "'''\n",
    "\n",
    "with open(\"transcription.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "transcription[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This snippet attempts to invoke a processing chain with a specific context and question. The context is set to the contents of a transcription, \n",
    "presumably from an audio or video source, and the question posed is \"Is reading papers a good idea?\". The use of a try-except block is crucial here \n",
    "for robust error handling. It ensures that if any part of the invocation process fails (for example, due to an issue with the model, the input data, \n",
    "or the connection), the exception is caught, and an error message is printed. This approach helps in diagnosing issues during the invocation process \n",
    "without crashing the program.\n",
    "'''\n",
    "\n",
    "try:\n",
    "    chain.invoke({\n",
    "        \"context\": transcription,\n",
    "        \"question\": \"Is reading papers a good idea?\"\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a half years, I've seen a lot of development specifically happening in the field of AI. If we consider Gen.D.V.A.I, if we consider the LLM models, if we consider LLM models, if we consider AI tools that are coming up in the market. And recently, I hope everybody has seen about Devon, which is the first AI software engineer. And obviously, applications like chat, GPT and the other competitors who are building amazing AI tools for images, for text and many more. Now, currently, you can actually see that in our life, I think everybody right now is probably using AI. So that is the reason why I've kept this title of this particular video that it's time to adopt AI in our lives. Now, when I say with respect to adopt, it is not like you just need to learn AI for getting a job or working in this specific field. Yes, if you are interested, you can also go in that specific path. But adoption of AI is really necessary in our life because at the end of the day, you know, whatever predictions, whatever forecasting, whatever achievements is basically happening in the field of AI is because of data. The more data that we have and obviously we're going to have a lot of amount of data as we go ahead because we are using social media platforms, we are using different different platforms altogether. Every day, every second, every minute data is getting increased exponentially. So it is necessary, guys, we're really need to adopt AI and we need to adopt in such a way that how we can use AI efficiently in our day-to-day activities. Now, from past four to five years, I have already completed five years uploading videos in YouTube channel and I've been working in the field of AI from 2014. And I've seen that kind of change and probably in the upcoming 10 years, AI will be deeply integrated with all our lives, whatever task we do, whatever, if you are even going outside, if you are traveling somewhere, some or the other way we are going to use some of the AI applications. And still, when I probably see in the job, job industries and all, there are a lot of openings with respect to AI. I've seen startups who are building some amazing ideas, they wanted to probably use these LLN models, solve some amazing use cases and all. Not only that, and this actually happens in each and every domain, I'm not just talking about one simple text domain or some other domain itself. Every domain and probably if you have seen in Shark Tank, any companies that are building this startup, one or some of the AI functionalities are definitely included. Now, even though in your software engineering team also you'll be seeing now, whatever software product companies are actually building, there will be a separate AI team to include some of the AI modules in those kind of software products. So this really shows the kind of development that is happening in the field is quite amazing. But one important thing that we really miss still is the kind of AI workforce that we have who can probably work in that. People are learning things, but what people are actually lacking is kind of implementation, like how they can specifically implement AI in those specific use cases and all. And as you all know, if you're following my channel, I always make sure that I upload a lot of videos for you with respect to practical implementation with respect to use cases and many more things. So still, if you think that many people will still say, hey, there are no jobs in AI and all, I've seen so many people getting placed in different different places and they're working specifically in AI use cases. If that is the kind of question that is coming in your mind, trust me, you're again lagging things. There is a very good article, I'll probably provide you the article link in the description of this particular video saying that why companies that wait to adopt AI may never catch up. So it's not only with respect to companies, I see companies are already doing that specific, you know, every company is including AI task in there. They're trying to integrate AI in this often modules in their application in their products, right. And this is with respect to both hardware and software. Similarly, what I feel is that people, if they are not adopting AI right now, again, they will be never be able to catch up. And this is what I feel and I'm able to see it guys. Trust me, I've been in this particular field from past 11 years, you know, the overall experience that I have in high industry somewhere around 12 to 13 years. I've seen that thing that how this particular development is basically happening. You can probably see the examples of companies like Nvidia, why Nvidia is becoming very popular, open AI, right. As soon as they came up with this charge, the application, why it is basically popular. Why Facebook, why Google why I mean why meta, right, why Google why companies like anthropic why companies like open AI are working in that specific space, you know, because the application is quite huge. Tell me how many people do not use charge, everybody use right why Google is probably also coming up with open source, LN models like gamma right why everybody is also in the race to create an open source model like meta came up with this slumber to why Google is actually coming up because they really want to stay in that race, you know, and yes, many people will talk about AGI applications are whether it is going to come in the future or not. But yes, in the future, you may see something like that, you know, like how Tony Stark says, hey, you are in open a new project, create this specific project, do this, that, do that automatically all those application will be able to do it by itself right. So those all things from the past 5 to 6 years, we have seen in all the movies and that thing now we can actually see that yes, it is getting possible. And there is a lot of research, a lot of money put into it right and the kind of scope that I probably see in the future is quite amazing. So it's time guys for you all to adopt AI in our day to day life, if you are not doing that trust me, you may never catch up. I have some of my friends who still say Chris, you are told me from past 4 to 5 years, you know, get into the AI field. If they had got over there, right now they would have done amazing things. My managers for my previous companies, you know, like when I started my, when I was working in sapien, they are asking me for help right now. Chris, how do we implement like this? I need to show my client like how I can actually integrate AI in this. And client trust me with respect to all over the world, they really like to see some use cases with respect to AI because at the end of the day, no, how efficient AI can actually be. And with respect to people who think that AI may take jobs and all, say the future of development looks something like this. You really need to be a jack of all trades, you really need to have knowledge with respect to multiple sectors. With respect to freshers, your college time is the most important period guys. Please do not waste your college time. You really need to learn multiple things over there. You need to be pro at each and everything. Let's say that you want to go into the software engineering business. Make sure that you learn front end back end databases, how you can actually use AI in that. So you really need to be the jack of all trades, right? Because at the end of the day, AI will also help you to do many more things. So if you have a knowledge of all these things, trust me by using AI, you'll be much more efficient then, right? So if this thing you really need to take care in mind and it's time, as I said to adopt AI, please make sure that you start using AI. You cannot ignore it. Trust me in that. So yes, this was it from my side. I hope you like this particular video. I'll see you all in the next video. Have a great day. Thank you. And I'll take care. Bye.\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "'''\n",
    "This snippet introduces the use of `TextLoader` from the `langchain_community` module, aimed at loading text data for processing. \n",
    "A `TextLoader` instance is created with a filename (\"transcription.txt\"), indicating the source file to load. The `load` method is then \n",
    "called to read the file's contents into `text_documents`, a variable that holds the loaded text data. This demonstrates a straightforward \n",
    "approach to importing textual data from a file, making it ready for further analysis or processing in Python.\n",
    "'''\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a half years, I've seen a lot of development specifically happening in the field of AI. If we consider Gen.D.V.A.I, if we consider the LLM models, if we consider LLM models, if we consider AI tools that are coming up in the market. And recently, I hope everybody has seen about Devon, which is the first AI software engineer. And obviously, applications like chat, GPT and the other competitors who are building amazing AI tools for images, for text and many more. Now, currently, you can actually see that in our life, I think everybody right now is probably using AI. So that is the reason why I've kept this title of this particular video that it's time to adopt AI in our lives. Now, when I say with respect to adopt, it is not like you just need to learn AI for getting a job or working in this specific field. Yes, if you are interested, you can also go in that specific path. But adoption of AI is\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"adoption of AI is really necessary in our life because at the end of the day, you know, whatever predictions, whatever forecasting, whatever achievements is basically happening in the field of AI is because of data. The more data that we have and obviously we're going to have a lot of amount of data as we go ahead because we are using social media platforms, we are using different different platforms altogether. Every day, every second, every minute data is getting increased exponentially. So it is necessary, guys, we're really need to adopt AI and we need to adopt in such a way that how we can use AI efficiently in our day-to-day activities. Now, from past four to five years, I have already completed five years uploading videos in YouTube channel and I've been working in the field of AI from 2014. And I've seen that kind of change and probably in the upcoming 10 years, AI will be deeply integrated with all our lives, whatever task we do, whatever, if you are even going outside, if\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"going outside, if you are traveling somewhere, some or the other way we are going to use some of the AI applications. And still, when I probably see in the job, job industries and all, there are a lot of openings with respect to AI. I've seen startups who are building some amazing ideas, they wanted to probably use these LLN models, solve some amazing use cases and all. Not only that, and this actually happens in each and every domain, I'm not just talking about one simple text domain or some other domain itself. Every domain and probably if you have seen in Shark Tank, any companies that are building this startup, one or some of the AI functionalities are definitely included. Now, even though in your software engineering team also you'll be seeing now, whatever software product companies are actually building, there will be a separate AI team to include some of the AI modules in those kind of software products. So this really shows the kind of development that is happening in the\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"is happening in the field is quite amazing. But one important thing that we really miss still is the kind of AI workforce that we have who can probably work in that. People are learning things, but what people are actually lacking is kind of implementation, like how they can specifically implement AI in those specific use cases and all. And as you all know, if you're following my channel, I always make sure that I upload a lot of videos for you with respect to practical implementation with respect to use cases and many more things. So still, if you think that many people will still say, hey, there are no jobs in AI and all, I've seen so many people getting placed in different different places and they're working specifically in AI use cases. If that is the kind of question that is coming in your mind, trust me, you're again lagging things. There is a very good article, I'll probably provide you the article link in the description of this particular video saying that why companies that\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"why companies that wait to adopt AI may never catch up. So it's not only with respect to companies, I see companies are already doing that specific, you know, every company is including AI task in there. They're trying to integrate AI in this often modules in their application in their products, right. And this is with respect to both hardware and software. Similarly, what I feel is that people, if they are not adopting AI right now, again, they will be never be able to catch up. And this is what I feel and I'm able to see it guys. Trust me, I've been in this particular field from past 11 years, you know, the overall experience that I have in high industry somewhere around 12 to 13 years. I've seen that thing that how this particular development is basically happening. You can probably see the examples of companies like Nvidia, why Nvidia is becoming very popular, open AI, right. As soon as they came up with this charge, the application, why it is basically popular. Why Facebook, why\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "'''\n",
    "Utilizing `RecursiveCharacterTextSplitter` from the `langchain` package, this code snippet demonstrates how to split longer text documents \n",
    "into smaller chunks for easier processing or analysis. The splitter is configured to divide the text into chunks of 100 characters with a \n",
    "20 character overlap between consecutive chunks. This approach can be particularly useful for handling large texts in tasks that require \n",
    "uniform input sizes, such as feeding data into machine learning models. The `.split_documents` method is applied to previously loaded text \n",
    "documents, and the first five chunks are retrieved to illustrate the output format and chunking effect.\n",
    "'''\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "text_splitter.split_documents(text_documents)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our specific application, let's use 1000 characters instead:\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the relevant chunks\n",
    "\n",
    "Let's generate embeddings for an arbitrary query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n",
      "[-0.001371190081765891, -0.03434698236453119, -0.011476094990116788, 0.0012773800454156574, -0.026166747008526288, 0.009230907949392044, -0.015660022937300136, 0.0017948988196774898, -0.011851335135517721, -0.03324627818637449]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate how embeddings work, let's first generate the embeddings for two different sentences:\n",
    "sentence1 = embeddings.embed_query(\"Mary's sister is Susana\")\n",
    "sentence2 = embeddings.embed_query(\"Pedro's mother is a teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91745489543827, 0.7680495517171415)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#use Cosine Similarity to calculate the similarity between the query and each of the sentences:\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# Initialize a DocArrayInMemorySearch vector store with a set of texts.\n",
    "# The texts are embedded using the previously defined OpenAIEmbeddings instance,\n",
    "# enabling efficient similarity search among the texts based on their semantic content.\n",
    "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"Mary's sister is Susana\",\n",
    "        \"John and Tommy are brothers\",\n",
    "        \"Patricia likes white cars\",\n",
    "        \"Pedro's mother is a teacher\",\n",
    "        \"Lucia drives an Audi\",\n",
    "        \"Mary has two siblings\",\n",
    "    ],\n",
    "    embedding=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Mary's sister is Susana\"), 0.9174549036927803),\n",
       " (Document(page_content='Mary has two siblings'), 0.9045440036524318),\n",
       " (Document(page_content='John and Tommy are brothers'), 0.8015357441152158)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting the vector store to the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Mary's sister is Susana\"),\n",
       " Document(page_content='Mary has two siblings'),\n",
       " Document(page_content='John and Tommy are brothers'),\n",
       " Document(page_content=\"Pedro's mother is a teacher\")]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Patricia likes white cars'),\n",
       "  Document(page_content='Lucia drives an Audi'),\n",
       "  Document(page_content=\"Pedro's mother is a teacher\"),\n",
       "  Document(page_content=\"Mary's sister is Susana\")],\n",
       " 'question': \"What color is Patricia's car?\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucia drives an Audi.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What car does Lucia drive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading transcription into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch at 0x1d9de630750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)\n",
    "vectorstore2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adopting AI refers to integrating artificial intelligence technology into various aspects of our daily lives and activities in order to utilize it efficiently and stay ahead of the technological advancements.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"what is adopt ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYUSH NATH TIWARI\\Desktop\\YouTube_RAG\\venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Explicitly set your API key here\n",
    "os.environ['PINECONE_API_KEY'] = 'd8cf6af7-33ad-4cff-aea4-e0131321de28'\n",
    "# Assuming 'gcp-starter' is a placeholder for your actual environment\n",
    "os.environ['PINECONE_API_ENV'] = 'gcp-starter'\n",
    "\n",
    "index_name = \"youtube-index\"\n",
    "\n",
    "# Ensure documents and embeddings are defined\n",
    "# documents = [...]\n",
    "# embeddings = [...]\n",
    "\n",
    "pinecone_vector_store = PineconeVectorStore.from_documents(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"going outside, if you are traveling somewhere, some or the other way we are going to use some of the AI applications. And still, when I probably see in the job, job industries and all, there are a lot of openings with respect to AI. I've seen startups who are building some amazing ideas, they wanted to probably use these LLN models, solve some amazing use cases and all. Not only that, and this actually happens in each and every domain, I'm not just talking about one simple text domain or some other domain itself. Every domain and probably if you have seen in Shark Tank, any companies that are building this startup, one or some of the AI functionalities are definitely included. Now, even though in your software engineering team also you'll be seeing now, whatever software product companies are actually building, there will be a separate AI team to include some of the AI modules in those kind of software products. So this really shows the kind of development that is happening in the\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"going outside, if you are traveling somewhere, some or the other way we are going to use some of the AI applications. And still, when I probably see in the job, job industries and all, there are a lot of openings with respect to AI. I've seen startups who are building some amazing ideas, they wanted to probably use these LLN models, solve some amazing use cases and all. Not only that, and this actually happens in each and every domain, I'm not just talking about one simple text domain or some other domain itself. Every domain and probably if you have seen in Shark Tank, any companies that are building this startup, one or some of the AI functionalities are definitely included. Now, even though in your software engineering team also you'll be seeing now, whatever software product companies are actually building, there will be a separate AI team to include some of the AI modules in those kind of software products. So this really shows the kind of development that is happening in the\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a half years, I've seen a lot of development specifically happening in the field of AI. If we consider Gen.D.V.A.I, if we consider the LLM models, if we consider LLM models, if we consider AI tools that are coming up in the market. And recently, I hope everybody has seen about Devon, which is the first AI software engineer. And obviously, applications like chat, GPT and the other competitors who are building amazing AI tools for images, for text and many more. Now, currently, you can actually see that in our life, I think everybody right now is probably using AI. So that is the reason why I've kept this title of this particular video that it's time to adopt AI in our lives. Now, when I say with respect to adopt, it is not like you just need to learn AI for getting a job or working in this specific field. Yes, if you are interested, you can also go in that specific path. But adoption of AI is\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_vector_store.similarity_search(\"what are llm models\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a half years, I've seen a lot of development specifically happening in the field of AI. If we consider Gen.D.V.A.I, if we consider the LLM models, if we consider LLM models, if we consider AI tools that are coming up in the market. And recently, I hope everybody has seen about Devon, which is the first AI software engineer. And obviously, applications like chat, GPT and the other competitors who are building amazing AI tools for images, for text and many more. Now, currently, you can actually see that in our life, I think everybody right now is probably using AI. So that is the reason why I've kept this title of this particular video that it's time to adopt AI in our lives. Now, when I say with respect to adopt, it is not like you just need to learn AI for getting a job or working in this specific field. Yes, if you are interested, you can also go in that specific path. But adoption of AI is\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"Hello, my name is Krish Nayak and welcome to my YouTube channel. So guys from the past one and a half years, I've seen a lot of development specifically happening in the field of AI. If we consider Gen.D.V.A.I, if we consider the LLM models, if we consider LLM models, if we consider AI tools that are coming up in the market. And recently, I hope everybody has seen about Devon, which is the first AI software engineer. And obviously, applications like chat, GPT and the other competitors who are building amazing AI tools for images, for text and many more. Now, currently, you can actually see that in our life, I think everybody right now is probably using AI. So that is the reason why I've kept this title of this particular video that it's time to adopt AI in our lives. Now, when I say with respect to adopt, it is not like you just need to learn AI for getting a job or working in this specific field. Yes, if you are interested, you can also go in that specific path. But adoption of AI is\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"adoption of AI is really necessary in our life because at the end of the day, you know, whatever predictions, whatever forecasting, whatever achievements is basically happening in the field of AI is because of data. The more data that we have and obviously we're going to have a lot of amount of data as we go ahead because we are using social media platforms, we are using different different platforms altogether. Every day, every second, every minute data is getting increased exponentially. So it is necessary, guys, we're really need to adopt AI and we need to adopt in such a way that how we can use AI efficiently in our day-to-day activities. Now, from past four to five years, I have already completed five years uploading videos in YouTube channel and I've been working in the field of AI from 2014. And I've seen that kind of change and probably in the upcoming 10 years, AI will be deeply integrated with all our lives, whatever task we do, whatever, if you are even going outside, if\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_vector_store.similarity_search(\"what are adopt ai\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
